Лавров Никита, РИ-230944

# Аугментации и работа с изображениями

### Задание 1: Стандартные аугментации torchvision

Был использован pipeline стандартных аугментаций с лекции с некоторым дополнением и редактированием. 

Оригинал

![AUG_OGIR](/lesson5/homework/images/original_imgs.png)

Результат применения каждой аугментации отдельно

![AUG_R](/lesson5/homework/images/aug_imgs.png)

Результат применения всех аугментаций вместе

![AUG_ALL](/lesson5/homework/images/all_aug.png)

На каждом изображении отчетливо видны различия и следы аугментации. 

# Задание 2: Кастомные аугментации

В utils/custom_augs.py были реализованы методы: 

Cлучайное размытие

![AUG_BLUR](/lesson5/homework/images/custom_aug/random_gaussian_blur.png)

Cлучайная перспектива, 

![AUG_PERSPECTIVE](/lesson5/homework/images/custom_aug/random_perspective_warp.png)

Cлучайная контрастность

![AUG_CONTRAST](/lesson5/homework/images/custom_aug/contrast.png)

Не на каждом изображении видны различия, тем не менее, они есть. 

Если визуально сравнивать с изнаально данными методами, то вряд ли кастомная аугментация даст высокий результат, а риск переобучения вырастет из-за схожести изображений. Однако вероятность можно контролировать, что уже может существенно повлиять на итог.

# Задание 3: Анализ датасета

Для анализа были построены гистограмма и scatter plot для наглядного уровень рассмотрения некоторых показателей датасета.

Количество

![COUNT](/lesson5/homework/images/analyse/count_image_hist.png)

Размеры

![SIZE](/lesson5/homework/images/analyse/size_image_scatter.png)

В данном датасете равномерное распределение классов изображений - ~30 штук.

Также присутствует значительный разброс как по ширине, так и по высоте изображений. Минимальные значения ширины - ~200 пикселей, максимальные - ~700 пикселей. По высоте разброс ещё больше - от ~200 до более чем 1200 пикселей. Заметны вертикальные скопления точек, особенно в районе ширины 500–600 пикселей. Это говорит о том, что многие изображения имеют одинаковую или очень близкую ширину, но различаются по высоте.

В целом, датасет содержит изображения с очень разными размерами и соотношениями сторон.

# Задание 4: Pipeline аугментаций

Был реализован класс AugmentationPipeline и конфигурации light, medium heavy. 

Далее продемонстрирована часть итоговых изображений

![LIGHT1](/lesson5/homework/images/augmentation_pipeline/pipeline_light_img3.png)


![MEDIUM1](/lesson5/homework/images/augmentation_pipeline/pipeline_medium_img0.png)

# Задание 5: Эксперимент с размерами 

Измерение зависимости различных показателей от размера наглядно видна в следующей таблице

| Размер  | Время загрузки (с) | Память (МБ) | Время аугментаций (с) |
|---------|--------------------|-------------|-----------------------|
| 64x64   | 0.44               | 8.42        | 0.02                  |
| 128x128 | 0.47               | 9.24        | 0.04                  |
| 224x224 | 0.52               | 15.12       | 0.08                  |
| 512x512 | 0.74               | 82.88       | 0.36                  |

Здесь заметна прямая корреляция между размером, временем и памятью. Также можно убедиться, взглянув на график

![SIZE_COMP](/lesson5/homework/images/sizes/size_experiment_results.png)

Отчётливо видно, что чем выше размер изображения, тем больше памяти и времени аугментации уходит на него, что в принципе очевидно.

# Задание 6: Дообучение предобученных моделей

Релузьтаты получились следующими

| Train Loss | Train Accuracy | Val Loss | Val Accuracy |
|------------|----------------|----------|--------------|
| 0.0640     | 0.9833         | 3.4209   | 0.6250       |

![TRAIN](/lesson5/homework/images/training_process.png)


- Train Loss (0.0640)

    Это очень низкое значение потерь. Оно указывает на то, что модель очень хорошо выучила тренировочные данные.

- Train Accuracy (98.33%)

    Это чрезвычайно высокая точность. Модель практически идеально классифицирует изображения из тренировочного набора.

- Val Loss (3.4209)

    Это очень высокое значение потерь по сравнению с тренировочными потерями. Большая разница между Train Loss и Val Loss — это классический признак переобучения.

- Val Accuracy (62.50%)

    Это заметно более низкое значение точности по сравнению с тренировочной точностью. Модель, которая почти идеально работает на тренировочных данных, показывает посредственный результат на валидационных.


Модель слишком хорошо запомнила тренировочные данные, включая шум и специфические особенности, которые не являются общими для всех данных. В результате она прекрасно справляется с данными, которые видела во время обучения, но плохо обобщается на новые.