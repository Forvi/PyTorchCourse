{
    "input_size": 784,
    "num_classes": 10,
    "layers": [
        {"type": "linear", "size": 512},
        {"type": "batchnorm"},
        {"type": "relu"},
        {"type": "dropout", "p": 0.5},
        {"type": "linear", "size": 256},
        {"type": "batchnorm"},
        {"type": "relu"},
        {"type": "dropout", "p": 0.5}
    ]
}
