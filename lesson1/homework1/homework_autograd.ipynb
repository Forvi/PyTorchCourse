{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b2cd2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82a948d",
   "metadata": {},
   "source": [
    "## Задание 2: Автоматическое дифференцирование"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ed54d5",
   "metadata": {},
   "source": [
    "2.1 Простые вычисления с градиентами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff65b28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходные векторы \n",
      "x:\n",
      "tensor([2., 3.]), \n",
      "y:\n",
      "tensor([4., 5.]), \n",
      "z:\n",
      "tensor([6., 7.])\n",
      "\n",
      "Градиенты: [ None, None, None ]\n",
      "df/dx = tensor([52., 76.])\n",
      "df/dy = tensor([32., 52.])\n",
      "df/dz = tensor([28., 44.])\n",
      "\n",
      "df/dx = tensor([52., 76.])\n",
      "df/dy = tensor([32., 52.])\n",
      "df/dz = tensor([28., 44.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([2., 3.], requires_grad=True)\n",
    "y = torch.tensor([4., 5.], requires_grad=True)\n",
    "z = torch.tensor([6., 7.], requires_grad=True)\n",
    "\n",
    "print(f'Исходные векторы \\nx:\\n{x.detach()}, \\ny:\\n{y.detach()}, \\nz:\\n{z.detach()}')\n",
    "print(f'\\nГрадиенты: [ {x.grad}, {y.grad}, {z.grad} ]') # Будут None, т.к ещё не была посчитана функция\n",
    "\n",
    "\n",
    "f = (x**2 + y**2 + z**2 + 2*x*y*z).sum() # f = f(x, y, z)\n",
    "f.backward()\n",
    "\n",
    "print(f\"df/dx = {x.grad}\")\n",
    "print(f\"df/dy = {y.grad}\") \n",
    "print(f\"df/dz = {z.grad}\")\n",
    "\n",
    "# Вычисление аналитически\n",
    "x_grad = 2*x + 2*y*z\n",
    "y_grad = 2*y + 2*x*z\n",
    "z_grad = 2*z + 2*x*y\n",
    "\n",
    "print(f\"\\ndf/dx = {x_grad.detach()}\") \n",
    "print(f\"df/dy = {y_grad.detach()}\") \n",
    "print(f\"df/dz = {z_grad.detach()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4770f7f3",
   "metadata": {},
   "source": [
    "2.2 Градиент функции потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ec24cdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10., 11., 12., 13., 14., 15., 16., 17., 18., 19.])\n",
      "tensor([12., 13., 14., 15., 16., 17., 18., 19., 20., 21.])\n",
      "\n",
      "MSE: 4.0\n",
      "Градиент w: -58.0\n",
      "Градиент b: -4.000000476837158\n"
     ]
    }
   ],
   "source": [
    "# MSE = (1/n) * Σ(y_pred - y_true)^2\n",
    "\n",
    "\n",
    "def my_mse(y_pred, y_true):\n",
    "    if not isinstance(y_pred, torch.Tensor) and not isinstance(y_true, torch.Tensor):\n",
    "        raise TypeError(\"Invalid type\")    \n",
    "    return (((y_pred - y_true) ** 2)).sum() / y_true.size()[0]\n",
    "\n",
    "\n",
    "x = torch.arange(10., 20.)\n",
    "y_true = torch.arange(12., 22.)\n",
    "\n",
    "print(x)\n",
    "print(y_true)\n",
    "\n",
    "w = torch.tensor(1.0, requires_grad=True) \n",
    "b = torch.tensor(0.0, requires_grad=True)\n",
    "\n",
    "y_pred = w * x + b\n",
    "mse = my_mse(y_pred, y_true)\n",
    "mse.backward()\n",
    "\n",
    "print(f'\\nMSE: {mse.detach()}')\n",
    "print(f'Градиент w: {w.grad}') \n",
    "print(f'Градиент b: {b.grad}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02c6a4d",
   "metadata": {},
   "source": [
    "2.3 Цепное правило"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7499c59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Аналитическое решение: \n",
      "tensor([ 21.2127, -83.7273,  77.7941,  82.6556])\n",
      "\n",
      "Автоградиент: \n",
      "tensor([ 21.2127, -83.7273,  77.7941,  82.6556])\n",
      "\n",
      "torch.autograd.grad: \n",
      "(tensor([ 21.2127, -83.7273,  77.7941,  82.6556]),)\n"
     ]
    }
   ],
   "source": [
    "# Реализуйте составную функцию: f(x) = sin(x^2 + 1)\n",
    "# Найдите градиент df/dx\n",
    "# Проверьте результат с помощью torch.autograd.grad\n",
    "\n",
    "x = torch.tensor([12., 53.2, 41.4, 84.1], requires_grad=True)\n",
    "f = torch.sin(x**2 + 1).sum()\n",
    "\n",
    "# f(x) = sin(x^2 + 1) -> df/dx = 2xcos(x^2 + 1)\n",
    "\n",
    "test = 2*x * torch.cos(x**2 + 1)\n",
    "print(f'Аналитическое решение: \\n{test.detach()}')\n",
    "\n",
    "f.backward()\n",
    "print(f'\\nАвтоградиент: \\n{x.grad}')\n",
    "\n",
    "# проверка torch.autograd.grad\n",
    "x = torch.tensor([12., 53.2, 41.4, 84.1], requires_grad=True)\n",
    "f = torch.sin(x**2 + 1).sum()\n",
    "\n",
    "ag = torch.autograd.grad(outputs=f, inputs=x)\n",
    "\n",
    "print(f'\\ntorch.autograd.grad: \\n{ag}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
